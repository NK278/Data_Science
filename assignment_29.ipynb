{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9457ab1-b86a-44fb-904e-7c72130b8b68",
   "metadata": {},
   "source": [
    "Q1 Explain the following with an example:\n",
    "C) Artificial IntKlligence\n",
    "B) Machine Learning,\n",
    "I) Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ebb4f-e0e4-4e47-aaea-22b18959c1a4",
   "metadata": {},
   "source": [
    "Ans: Certainly! Let me explain each concept with an example:\n",
    "\n",
    "A) **Artificial Intelligence (AI):**\n",
    "   - **Definition:** Artificial Intelligence refers to the simulation of human intelligence in machines that are programmed to think and mimic human-like cognitive functions such as problem-solving, learning, and decision-making.\n",
    "   - **Example:** Chatbots are a common example of AI. These are computer programs that use natural language processing and machine learning algorithms to understand and respond to user queries. For instance, a customer support chatbot can analyze customer questions and provide relevant answers, learning and improving its responses over time.\n",
    "\n",
    "B) **Machine Learning (ML):**\n",
    "   - **Definition:** Machine Learning is a subset of AI that focuses on the development of algorithms and statistical models that enable computers to improve their performance on a specific task without being explicitly programmed.\n",
    "   - **Example:** Consider a spam filter for emails. In traditional programming, rules for identifying spam emails would need to be explicitly defined. In contrast, a machine learning approach involves training a model on a dataset of emails, where it learns patterns and characteristics of spam and non-spam emails. Once trained, the model can classify new, unseen emails as spam or not based on what it has learned.\n",
    "\n",
    "C) **Deep Learning (DL):**\n",
    "   - **Definition:** Deep Learning is a subset of machine learning that involves artificial neural networks, inspired by the structure and function of the human brain. It is particularly effective in handling large and complex datasets.\n",
    "   - **Example:** Image recognition is a common application of deep learning. A deep neural network can be trained to recognize objects in images. For instance, a deep learning model for image recognition could be trained on a dataset of thousands of labeled images of cats and dogs. After training, the model can accurately classify new images as either cats or dogs based on the features it has learned.\n",
    "\n",
    "In summary, Artificial Intelligence is the broader concept of machines exhibiting human-like intelligence, Machine Learning is a subset of AI that focuses on self-improvement through data-driven learning, and Deep Learning is a subset of ML that uses neural networks to handle complex tasks, often with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4f005-734a-44ff-a441-0fc20b50ba11",
   "metadata": {},
   "source": [
    "Q2 What is supervised learning? List some examples of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5bbf62-eda0-44a7-82f0-ba94c70cead1",
   "metadata": {},
   "source": [
    "Ans: **Supervised learning** is a type of machine learning where the algorithm is trained on a labeled dataset, meaning that the input data used for training is paired with corresponding output labels. The goal is for the algorithm to learn a mapping from inputs to outputs, making predictions or decisions based on new, unseen data.\n",
    "\n",
    "In supervised learning, the algorithm is provided with a set of input-output pairs, and during training, it adjusts its parameters to minimize the difference between its predictions and the actual labeled outputs. Once trained, the model can make predictions on new, unseen data.\n",
    "\n",
    "Here are some examples of supervised learning:\n",
    "\n",
    "1. **Image Classification:**\n",
    "   - *Example:* Given a dataset of images with labeled categories (e.g., cats and dogs), the algorithm learns to classify new images into those categories.\n",
    "\n",
    "2. **Speech Recognition:**\n",
    "   - *Example:* Training a model to recognize spoken words or phrases by providing it with a dataset of audio recordings paired with transcriptions.\n",
    "\n",
    "3. **Text Classification:**\n",
    "   - *Example:* Classifying emails as spam or not spam based on a dataset of emails labeled with their corresponding categories.\n",
    "\n",
    "4. **Regression Analysis:**\n",
    "   - *Example:* Predicting the price of a house based on features such as square footage, number of bedrooms, and location using a dataset of labeled housing prices.\n",
    "\n",
    "5. **Handwriting Recognition:**\n",
    "   - *Example:* Teaching a model to recognize handwritten digits by training it on a dataset of labeled images of handwritten numbers (e.g., the MNIST dataset).\n",
    "\n",
    "6. **Credit Scoring:**\n",
    "   - *Example:* Predicting whether a loan applicant is likely to default or not based on historical data of loan applicants with known outcomes.\n",
    "\n",
    "7. **Medical Diagnosis:**\n",
    "   - *Example:* Diagnosing diseases based on patient data, such as symptoms, medical history, and test results, with a dataset of labeled diagnoses.\n",
    "\n",
    "8. **Fraud Detection:**\n",
    "   - *Example:* Identifying fraudulent transactions in a credit card dataset by learning patterns from labeled examples of both legitimate and fraudulent transactions.\n",
    "\n",
    "9. **Language Translation:**\n",
    "   - *Example:* Training a model to translate text from one language to another using a dataset of parallel texts in both languages.\n",
    "\n",
    "10. **Customer Churn Prediction:**\n",
    "    - *Example:* Predicting whether a customer is likely to churn (stop using a service) based on historical customer data with labeled churn outcomes.\n",
    "\n",
    "These examples illustrate the diverse applications of supervised learning across various domains. In each case, the algorithm learns to make predictions or decisions based on the labeled data it has been trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24384f9-f1de-4a70-876b-07bef78894e7",
   "metadata": {},
   "source": [
    "Q3 What is unsupervised learning? List some examples of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174a557-9206-46fe-8acb-d92427e4c53e",
   "metadata": {},
   "source": [
    "Ans: **Unsupervised learning** is a type of machine learning where the algorithm is given input data without explicit output labels. The system tries to learn the patterns and the structure from the data without guidance on what the correct output should be. The goal of unsupervised learning is often to explore the inherent structure of the data, find hidden patterns, or group similar data points.\n",
    "\n",
    "Here are some examples of unsupervised learning:\n",
    "\n",
    "1. **Clustering:**\n",
    "   - *Example:* Grouping similar documents together based on their content, without providing explicit categories. K-means clustering is a popular algorithm for this task.\n",
    "\n",
    "2. **Dimensionality Reduction:**\n",
    "   - *Example:* Reducing the number of features in a dataset while retaining its essential information. Principal Component Analysis (PCA) is a common technique for dimensionality reduction.\n",
    "\n",
    "3. **Anomaly Detection:**\n",
    "   - *Example:* Identifying unusual patterns or outliers in data, such as detecting fraudulent transactions in a credit card dataset where most transactions are legitimate.\n",
    "\n",
    "4. **Association Rule Learning:**\n",
    "   - *Example:* Discovering interesting relationships or associations among variables in a dataset, like finding common purchasing patterns in a retail dataset.\n",
    "\n",
    "5. **Generative Models:**\n",
    "   - *Example:* Creating new data samples that resemble the training data. Generative Adversarial Networks (GANs) are an example of generative models used for tasks like generating realistic images.\n",
    "\n",
    "6. **Hierarchical Clustering:**\n",
    "   - *Example:* Creating a tree-like hierarchy of clusters, where similar data points are grouped together at different levels of granularity.\n",
    "\n",
    "7. **Density Estimation:**\n",
    "   - *Example:* Estimating the probability density function of a dataset, which can be used for anomaly detection or understanding the underlying distribution of the data.\n",
    "\n",
    "8. **Word Embeddings:**\n",
    "   - *Example:* Representing words in a continuous vector space based on their contextual usage, as seen in Word2Vec or GloVe models.\n",
    "\n",
    "9. **Recommendation Systems:**\n",
    "   - *Example:* Suggesting products or content to users based on their preferences, without explicit user ratings. Collaborative filtering is an unsupervised technique often used for recommendation systems.\n",
    "\n",
    "10. **Neural Network Autoencoders:**\n",
    "    - *Example:* Training a neural network to reconstruct input data, and then using the learned representation for tasks such as feature extraction or data compression.\n",
    "\n",
    "Unsupervised learning methods are valuable for exploring and understanding the inherent structure of data, particularly when labeled examples are scarce or unavailable. These techniques play a crucial role in various fields, including data exploration, pattern discovery, and feature learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2b6f-2343-4743-a3f1-f962363bb22d",
   "metadata": {},
   "source": [
    "Q4 What is the difference between AI, ML, DL, and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d4222-b09d-48e8-aee7-07922cfa506e",
   "metadata": {},
   "source": [
    "Ans: AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are related concepts, but they represent different aspects of the broader field of computer science. Here's a brief overview of the differences:\n",
    "\n",
    "1. **Artificial Intelligence (AI):**\n",
    "   - **Definition:** AI refers to the development of computer systems that can perform tasks that typically require human intelligence. It encompasses a wide range of techniques and approaches to enable machines to simulate human-like cognition.\n",
    "   - **Example:** Natural language processing, computer vision, speech recognition, and problem-solving are examples of AI applications.\n",
    "\n",
    "2. **Machine Learning (ML):**\n",
    "   - **Definition:** ML is a subset of AI that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. ML systems learn from data and improve their performance over time.\n",
    "   - **Example:** Predictive modeling, classification, regression, clustering, and recommendation systems are common ML applications.\n",
    "\n",
    "3. **Deep Learning (DL):**\n",
    "   - **Definition:** DL is a subset of ML that uses neural networks with multiple layers (deep neural networks) to learn and represent complex patterns in data. It is particularly effective for tasks involving large datasets.\n",
    "   - **Example:** Image and speech recognition, natural language processing, and autonomous vehicles often leverage deep learning techniques.\n",
    "\n",
    "4. **Data Science (DS):**\n",
    "   - **Definition:** DS is a multidisciplinary field that combines techniques from statistics, mathematics, computer science, and domain expertise to extract insights and knowledge from data. It encompasses a broader set of activities beyond machine learning, including data cleaning, visualization, and interpretation.\n",
    "   - **Example:** Exploratory data analysis, predictive modeling, and extracting actionable insights from large datasets are common activities in data science.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- **AI** is the overarching field focused on creating intelligent machines.\n",
    "- **ML** is a subset of AI that involves systems learning from data to improve their performance.\n",
    "- **DL** is a subset of ML that uses deep neural networks for complex pattern recognition.\n",
    "- **DS** is a multidisciplinary field that involves extracting insights and knowledge from data using various techniques, including ML.\n",
    "\n",
    "These terms are often used together, as they complement each other in solving complex problems and building intelligent systems. AI encompasses both traditional rule-based systems and learning-based systems (ML and DL), while DS provides the tools and methods to extract valuable knowledge from data in various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6bf62b-d931-44c7-9c09-a9ab8a316ccd",
   "metadata": {},
   "source": [
    "Q5 What are the main differences between supervised, unsupervised, and semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30f4ce-b371-4b2c-ad35-bc5c1e1de91f",
   "metadata": {},
   "source": [
    "Ans: The main differences between supervised learning, unsupervised learning, and semi-supervised learning lie in the type of training data they use and the nature of the learning process. Here are the key distinctions:\n",
    "\n",
    "1. **Supervised Learning:**\n",
    "   - **Training Data:** In supervised learning, the algorithm is trained on a labeled dataset, where each input is associated with the corresponding output (target or label).\n",
    "   - **Learning Objective:** The goal is to learn a mapping from inputs to outputs, making predictions or classifications on new, unseen data.\n",
    "   - **Example:** Image classification, regression analysis, and spam detection are common applications of supervised learning.\n",
    "\n",
    "2. **Unsupervised Learning:**\n",
    "   - **Training Data:** Unsupervised learning uses an unlabeled dataset, meaning that the algorithm is provided with input data without explicit output labels.\n",
    "   - **Learning Objective:** The goal is to discover patterns, structures, or relationships within the data without guidance on the correct output.\n",
    "   - **Example:** Clustering, dimensionality reduction, and generative modeling are typical tasks in unsupervised learning.\n",
    "\n",
    "3. **Semi-Supervised Learning:**\n",
    "   - **Training Data:** Semi-supervised learning combines elements of both supervised and unsupervised learning. The algorithm is trained on a dataset that includes both labeled and unlabeled examples.\n",
    "   - **Learning Objective:** The model aims to use both labeled and unlabeled data to improve its performance. It may leverage the structure and patterns learned from the unlabeled data to enhance its understanding of the labeled data.\n",
    "   - **Example:** In a scenario where collecting labeled data is expensive or time-consuming, semi-supervised learning can be useful. For instance, if you have a small labeled dataset of images with cats and dogs, and a large unlabeled dataset, semi-supervised learning could involve leveraging the unlabeled data to improve the model's performance on the cat and dog classification task.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- **Supervised learning** relies on labeled data to learn the relationship between inputs and outputs.\n",
    "- **Unsupervised learning** explores patterns and structures in unlabeled data without specific output guidance.\n",
    "- **Semi-supervised learning** combines labeled and unlabeled data to enhance model training, especially when obtaining labeled data is challenging or expensive.\n",
    "\n",
    "The choice between these approaches depends on the availability and cost of labeled data, as well as the specific goals of the learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28253211-b375-4cd3-aa16-d6bdf7c45ac3",
   "metadata": {},
   "source": [
    "Q6 What is train, test and validation split? Explain the importance of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659a7cf-62fa-48b5-98ac-e005615eb289",
   "metadata": {},
   "source": [
    "Ans: In machine learning, the terms \"train,\" \"test,\" and \"validation\" refer to different subsets of a dataset used for various stages of model development and evaluation. These splits are crucial for building robust and generalizable machine learning models. Let's explore the meaning and importance of each term:\n",
    "\n",
    "1. **Training Set:**\n",
    "   - **Definition:** The training set is a subset of the dataset used to train the machine learning model. The model learns the patterns, relationships, and features in the data by adjusting its parameters during the training process.\n",
    "   - **Importance:** The training set is essential for teaching the model how to make predictions or classifications. A well-trained model should be capable of generalizing its knowledge to new, unseen data.\n",
    "\n",
    "2. **Test Set:**\n",
    "   - **Definition:** The test set is a separate subset of the dataset that the model has not seen during training. It is used to evaluate the model's performance and assess how well it generalizes to new, unseen data.\n",
    "   - **Importance:** The test set provides an unbiased evaluation of the model's performance on data it hasn't encountered before. It helps assess whether the model has learned meaningful patterns or if it has merely memorized the training data (overfitting).\n",
    "\n",
    "3. **Validation Set:**\n",
    "   - **Definition:** The validation set is an additional subset of the dataset that is used during the model development phase for hyperparameter tuning and model selection. It helps prevent overfitting to the training set and guides the fine-tuning of the model.\n",
    "   - **Importance:** During the training process, models may be fine-tuned using the validation set to optimize their performance. The validation set acts as a safeguard against overfitting, as it provides an independent dataset not used for training. It allows the practitioner to adjust hyperparameters without introducing bias from the test set.\n",
    "\n",
    "**Importance of Each Term:**\n",
    "- **Training Set:** It is crucial for teaching the model and allowing it to learn the underlying patterns in the data. The model adjusts its parameters based on the information in the training set.\n",
    "  \n",
    "- **Test Set:** It is essential for assessing the model's generalization performance on new, unseen data. It helps identify potential issues such as overfitting and provides an unbiased evaluation of the model's effectiveness.\n",
    "\n",
    "- **Validation Set:** It is used for model selection and hyperparameter tuning during the training phase. The validation set helps prevent overfitting by providing an independent dataset for fine-tuning the model.\n",
    "\n",
    "The proper use of these sets helps ensure that machine learning models generalize well to new, real-world data and do not merely memorize the training examples. This process is known as \"train-test-validation split\" and is a fundamental practice in the development and evaluation of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad95807-cf7e-4cad-b546-aba426c528bb",
   "metadata": {},
   "source": [
    "Q7 How can unsupervised learning be used in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31cd0a-4165-44b4-9379-6c676f67a677",
   "metadata": {},
   "source": [
    "Ans: Unsupervised learning is a powerful approach for anomaly detection, as it allows systems to identify patterns in data without explicitly labeled instances of normal and anomalous behavior. Here's how unsupervised learning can be applied to anomaly detection:\n",
    "\n",
    "1. **Density-Based Methods:**\n",
    "   - **Approach:** Density-based methods, such as DBSCAN (Density-Based Spatial Clustering of Applications with Noise), identify regions of high data density. Data points that fall outside these dense regions are considered anomalies.\n",
    "   - **Application:** DBSCAN, for instance, can be used to identify clusters in the data and classify points that do not belong to any cluster as anomalies.\n",
    "\n",
    "2. **Clustering Techniques:**\n",
    "   - **Approach:** Unsupervised clustering methods, like K-means or hierarchical clustering, group similar data points together. Points that do not fit well into any cluster or are distant from all clusters may be considered anomalies.\n",
    "   - **Application:** Clustering techniques can help identify anomalies by assessing how well data points fit into established clusters.\n",
    "\n",
    "3. **Autoencoders:**\n",
    "   - **Approach:** Autoencoders are a type of neural network used for dimensionality reduction. The model learns to encode input data into a lower-dimensional representation and then decode it back to the original form. Anomalies may result in higher reconstruction errors.\n",
    "   - **Application:** Higher reconstruction errors for certain data points indicate that the model struggled to accurately reconstruct those points, suggesting anomalies.\n",
    "\n",
    "4. **One-Class SVM (Support Vector Machine):**\n",
    "   - **Approach:** One-Class SVM is a type of support vector machine designed for binary classification with only one class. It learns the distribution of normal data during training and identifies anomalies as instances that deviate from this distribution during testing.\n",
    "   - **Application:** One-Class SVM is useful when the majority of the data is normal, and anomalies are expected to be rare.\n",
    "\n",
    "5. **Isolation Forest:**\n",
    "   - **Approach:** Isolation Forest is an ensemble learning method that isolates anomalies by randomly selecting features and building trees to isolate anomalies in shorter paths.\n",
    "   - **Application:** Isolation Forest is efficient for identifying anomalies, especially in high-dimensional datasets.\n",
    "\n",
    "6. **Principal Component Analysis (PCA):**\n",
    "   - **Approach:** PCA is a dimensionality reduction technique that transforms data into a lower-dimensional space. Anomalies may be detected by identifying data points with large reconstruction errors.\n",
    "   - **Application:** By analyzing the principal components and their contributions, anomalies can be identified as data points that do not conform to the general pattern in the lower-dimensional space.\n",
    "\n",
    "**Key Considerations:**\n",
    "- **Feature Selection:** Choose relevant features that capture the characteristics of normal behavior and potential anomalies.\n",
    "  \n",
    "- **Model Evaluation:** Assess the performance of the unsupervised learning method using appropriate metrics, such as precision, recall, or the area under the Receiver Operating Characteristic (ROC) curve.\n",
    "\n",
    "- **Threshold Setting:** Determine a suitable threshold for anomaly detection based on the characteristics of the data and the chosen algorithm.\n",
    "\n",
    "Unsupervised learning methods for anomaly detection are valuable when labeled data for anomalies is scarce or unavailable. These techniques allow systems to automatically learn the normal behavior of a system or process and identify deviations from that norm as anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b1558-6b45-4432-95bd-f8a9ea16dab6",
   "metadata": {},
   "source": [
    "Q8 List down some commonly used supervised learning algorithms and unsupervised learning\n",
    "algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c07c5-feed-4444-987f-628aa04f3c6b",
   "metadata": {},
   "source": [
    "Ans: Certainly! Here are some commonly used supervised learning algorithms and unsupervised learning algorithms:\n",
    "\n",
    "### Supervised Learning Algorithms:\n",
    "\n",
    "1. **Linear Regression:**\n",
    "   - Used for regression tasks, predicting a continuous output based on input features.\n",
    "\n",
    "2. **Logistic Regression:**\n",
    "   - Used for binary classification tasks, predicting the probability of an instance belonging to a particular class.\n",
    "\n",
    "3. **Decision Trees:**\n",
    "   - Used for both classification and regression tasks, building a tree structure to make decisions based on input features.\n",
    "\n",
    "4. **Random Forest:**\n",
    "   - Ensemble method that builds multiple decision trees to improve predictive accuracy and control overfitting.\n",
    "\n",
    "5. **Support Vector Machines (SVM):**\n",
    "   - Used for classification and regression, aiming to find a hyperplane that best separates classes in feature space.\n",
    "\n",
    "6. **K-Nearest Neighbors (KNN):**\n",
    "   - Used for classification and regression, making predictions based on the majority class or average of k-nearest data points.\n",
    "\n",
    "7. **Naive Bayes:**\n",
    "   - Probabilistic algorithm based on Bayes' theorem, commonly used for classification tasks, especially in natural language processing.\n",
    "\n",
    "8. **Neural Networks:**\n",
    "   - Deep learning models with multiple layers of interconnected nodes (neurons) used for various tasks such as image recognition, natural language processing, and more.\n",
    "\n",
    "9. **Gradient Boosting (e.g., XGBoost, LightGBM):**\n",
    "   - Ensemble method that builds a series of weak models to create a strong predictive model, often used for classification and regression tasks.\n",
    "\n",
    "10. **Linear Discriminant Analysis (LDA):**\n",
    "    - Used for dimensionality reduction and classification, finding the linear combinations of features that best separate classes.\n",
    "\n",
    "### Unsupervised Learning Algorithms:\n",
    "\n",
    "1. **K-Means Clustering:**\n",
    "   - Divides the dataset into k clusters based on similarity, aiming to minimize intra-cluster variance.\n",
    "\n",
    "2. **Hierarchical Clustering:**\n",
    "   - Creates a hierarchy of clusters, forming a tree-like structure known as a dendrogram.\n",
    "\n",
    "3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**\n",
    "   - Identifies clusters based on the density of data points, handling outliers as noise.\n",
    "\n",
    "4. **PCA (Principal Component Analysis):**\n",
    "   - Used for dimensionality reduction, transforming data into a lower-dimensional space while retaining as much variance as possible.\n",
    "\n",
    "5. **Autoencoders:**\n",
    "   - Neural network models designed for dimensionality reduction and feature learning, often used in unsupervised scenarios.\n",
    "\n",
    "6. **Gaussian Mixture Models (GMM):**\n",
    "   - Represents the distribution of data as a mixture of Gaussian distributions, useful for density estimation.\n",
    "\n",
    "7. **Isolation Forest:**\n",
    "   - An ensemble method for anomaly detection, isolating anomalies by constructing isolation trees.\n",
    "\n",
    "8. **Apriori Algorithm:**\n",
    "   - Used for association rule mining to discover interesting relationships among variables in large datasets.\n",
    "\n",
    "9. **SOM (Self-Organizing Maps):**\n",
    "   - Neural network-based algorithm for clustering and visualization of high-dimensional data.\n",
    "\n",
    "10. **t-SNE (t-Distributed Stochastic Neighbor Embedding):**\n",
    "    - Technique for dimensionality reduction and visualization of high-dimensional data, preserving local similarities.\n",
    "\n",
    "These algorithms cover a broad range of tasks and are applied in diverse domains, depending on the characteristics of the data and the specific goals of the machine learning project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
