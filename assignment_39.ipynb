{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fbd301-5421-44b3-9fdb-eb2e10399a9d",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77053b25-c6c2-4c79-a22f-c575a1902a3b",
   "metadata": {},
   "source": [
    "Ans: Analysis of Variance (ANOVA) is a statistical method used to compare means across multiple groups. To ensure the validity of ANOVA results, several assumptions need to be satisfied. Here are the key assumptions for the one-way ANOVA:\n",
    "\n",
    "1. **Independence of Observations:**\n",
    "   - **Assumption:** The observations within each group and between groups should be independent.\n",
    "   - **Example Violation:** If the observations are not independent, such as in a repeated measures design where the same subjects are used in each group, it can violate this assumption.\n",
    "\n",
    "2. **Normality:**\n",
    "   - **Assumption:** The residuals (the differences between observed and predicted values) should be approximately normally distributed.\n",
    "   - **Example Violation:** If the residuals are not normally distributed, it can affect the reliability of ANOVA results, especially in small sample sizes.\n",
    "\n",
    "3. **Homogeneity of Variances (Homoscedasticity):**\n",
    "   - **Assumption:** The variances of the residuals should be roughly equal across all groups.\n",
    "   - **Example Violation:** If the variances are not homogeneous, it can lead to inflated Type I error rates and affect the reliability of the F-test. This is more critical in one-way ANOVA, less so in larger sample sizes or when sample sizes are approximately equal.\n",
    "\n",
    "4. **Interval or Ratio Data:**\n",
    "   - **Assumption:** The dependent variable should be measured on an interval or ratio scale.\n",
    "   - **Example Violation:** If the dependent variable is measured on a nominal or ordinal scale, using ANOVA may not be appropriate.\n",
    "\n",
    "5. **Equality of Group Sizes (for One-Way ANOVA):**\n",
    "   - **Assumption:** The sample sizes in each group should be approximately equal.\n",
    "   - **Example Violation:** If the group sizes are highly unequal, it may impact the power of the ANOVA and make the results less reliable.\n",
    "\n",
    "6. **Random Sampling (for Inferential Statistics):**\n",
    "   - **Assumption:** The samples should be randomly selected from the population.\n",
    "   - **Example Violation:** If the sampling is not random, there may be issues with generalizing the results to the broader population.\n",
    "\n",
    "When these assumptions are violated, alternative statistical methods or transformations of the data may be considered. Additionally, robust ANOVA techniques exist to address violations of assumptions in certain situations. It's essential to assess the assumptions and, if violated, interpret the ANOVA results cautiously or explore alternative analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283e1e1-db01-460d-87fa-15b9bc285334",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8ca92-a064-4888-98c2-cb33aeaacb4d",
   "metadata": {},
   "source": [
    "Ans: Analysis of Variance (ANOVA) is a statistical method used to analyze the differences among group means in a sample. There are three main types of ANOVA, each designed to address different experimental designs and research questions:\n",
    "\n",
    "1. **One-Way ANOVA:**\n",
    "   - **Use Case:** One-way ANOVA is used when there is one independent variable (factor) with more than two levels or groups, and the goal is to determine if there are any statistically significant differences among the group means.\n",
    "   - **Example:** Testing if there is a significant difference in the mean scores of three or more groups of students who received different teaching methods.\n",
    "\n",
    "2. **Two-Way ANOVA:**\n",
    "   - **Use Case:** Two-way ANOVA is an extension of one-way ANOVA that involves two independent variables (factors). It is used when there are two categorical independent variables, and the researcher wants to examine the influence of each variable on the dependent variable and their potential interaction.\n",
    "   - **Example:** Investigating if there are differences in exam scores based on both teaching method and gender.\n",
    "\n",
    "3. **Repeated Measures ANOVA:**\n",
    "   - **Use Case:** Repeated measures ANOVA is used when the same subjects are used for each treatment or condition. It is appropriate when measurements are taken at multiple time points or under multiple conditions on the same set of subjects.\n",
    "   - **Example:** Assessing if there is a significant change in participants' blood pressure levels under different drug treatments over time.\n",
    "\n",
    "Each type of ANOVA has its specific use case and addresses different research questions. Choosing the appropriate ANOVA method depends on the experimental design and the nature of the independent variables. It's essential to carefully consider the experimental design and characteristics of the data before selecting the ANOVA method that best fits the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cf8bc-101d-4142-8171-0f6cc2fcc6c3",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61e413-d23c-49ab-9ae0-8cba580b6ffc",
   "metadata": {},
   "source": [
    "Ans: The partitioning of variance in Analysis of Variance (ANOVA) refers to the decomposition of the total variance observed in the data into different components, each associated with specific sources of variability. Understanding this concept is crucial as it provides insights into the contributions of different factors to the overall variability in the dependent variable. The total variance observed in the data can be decomposed into the following components:\n",
    "\n",
    "1. **Between-Group Variance (SSB):**\n",
    "   - Represents the variability between the group means.\n",
    "   - Calculated as the sum of squared differences between each group mean and the overall mean, each multiplied by the number of observations in the group.\n",
    "\n",
    "2. **Within-Group Variance (SSW):**\n",
    "   - Represents the variability within each group.\n",
    "   - Calculated as the sum of squared differences between individual observations and their group mean within each group.\n",
    "\n",
    "3. **Total Variance (SST):**\n",
    "   - The overall variability in the data, which is the sum of the between-group variance and the within-group variance.\n",
    "   - Calculated as the sum of squared differences between each observation and the overall mean.\n",
    "\n",
    "The partitioning of variance is typically summarized in the ANOVA table, which includes the degrees of freedom, sum of squares, mean squares, and F-statistic. The F-statistic is calculated by taking the ratio of the between-group mean square to the within-group mean square.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "- **Identifying Sources of Variation:** It helps identify whether the variability in the dependent variable is primarily due to differences between groups or within groups. This information is essential for interpreting the results of ANOVA.\n",
    "\n",
    "- **Assessing Significance:** By comparing the between-group variance to the within-group variance, ANOVA determines whether the observed differences among group means are statistically significant.\n",
    "\n",
    "- **Interpreting Effect Size:** The ratio of between-group variance to within-group variance provides a measure of effect size, indicating the proportion of total variability explained by the independent variable.\n",
    "\n",
    "- **Guiding Further Analysis:** Understanding the partitioning of variance can guide further analyses, such as post hoc tests, to identify specific group differences.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA provides a structured way to analyze and interpret the sources of variability in the data, enabling researchers to draw meaningful conclusions about the effects of independent variables on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c2093-2113-44e5-a8b6-a28205c010fb",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd467f01-9006-4aa8-9bc8-d517f8857167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 661.7333333333333\n",
      "Explained Sum of Squares (SSE): 594.5333333333335\n",
      "Residual Sum of Squares (SSR): 67.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "group1 = np.array([10, 12, 15, 8, 11])\n",
    "group2 = np.array([18, 20, 22, 17, 21])\n",
    "group3 = np.array([25, 28, 24, 26, 30])\n",
    "\n",
    "# Combine the data into a single array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = len(group1) * (mean_group1 - overall_mean)**2 + \\\n",
    "      len(group2) * (mean_group2 - overall_mean)**2 + \\\n",
    "      len(group3) * (mean_group3 - overall_mean)**2\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = np.sum((group1 - mean_group1)**2) + np.sum((group2 - mean_group2)**2) + np.sum((group3 - mean_group3)**2)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Sum of Squares (SST): {sst}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {sse}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {ssr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b3736-2602-4ee2-8e40-8c16e3ad9524",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834e64c8-c1ae-403a-afbf-f810cd27d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor1: 266.6666666666663\n",
      "Main Effect of Factor2: 6.3333333333333295\n",
      "Interaction Effect: 7.166666666666708\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "data = {\n",
    "    'Factor1': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'Factor2': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Response': [10, 12, 15, 18, 20, 22, 25, 28, 24]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Response ~ Factor1 * Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq'] / anova_table.loc['Factor1', 'df']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq'] / anova_table.loc['Factor2', 'df']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq'] / anova_table.loc['Factor1:Factor2', 'df']\n",
    "\n",
    "# Print the results\n",
    "print(f\"Main Effect of Factor1: {main_effect_factor1}\")\n",
    "print(f\"Main Effect of Factor2: {main_effect_factor2}\")\n",
    "print(f\"Interaction Effect: {interaction_effect}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5348da-f5c3-4ddf-b081-1c4e319cf99a",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6b7cd-2d63-4daf-92cf-25de1cd84701",
   "metadata": {},
   "source": [
    "Ans: In a one-way ANOVA, the F-statistic is used to test whether there are significant differences among the means of three or more groups. The associated p-value helps determine the statistical significance of the observed differences. Here's how you can interpret the results:\n",
    "\n",
    "1. **F-Statistic:**\n",
    "   - The F-statistic is a ratio of variances. In the context of ANOVA, it compares the variability between group means to the variability within groups.\n",
    "   - A higher F-statistic suggests that the variability between group means is larger relative to the variability within groups.\n",
    "\n",
    "2. **P-Value:**\n",
    "   - The p-value associated with the F-statistic indicates the probability of observing such extreme results (or more extreme) under the assumption that the null hypothesis is true.\n",
    "   - A low p-value (typically below the chosen significance level, e.g., 0.05) suggests that the observed differences are statistically significant.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- **Null Hypothesis (H0):** There is no significant difference among the group means (all population means are equal).\n",
    "- **Alternative Hypothesis (H1):** There is a significant difference among the group means (at least one population mean is different).\n",
    "\n",
    "In your case:\n",
    "\n",
    "- **F-Statistic:** 5.23\n",
    "- **P-Value:** 0.02\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- The F-statistic of 5.23 indicates that there are differences among the group means.\n",
    "- The p-value of 0.02 is below the typical significance level of 0.05, suggesting that the observed differences are statistically significant.\n",
    "\n",
    "**Conclusion:**\n",
    "Based on the results, you would reject the null hypothesis and conclude that there are significant differences among the group means. However, the specific interpretation of which groups are different would require additional post hoc tests or further analysis.\n",
    "\n",
    "Keep in mind that statistical significance does not necessarily imply practical significance, and it's important to consider the context of the study and the effect size when interpreting the results. Additionally, the assumptions of ANOVA (independence, normality, and homogeneity of variances) should be checked to ensure the validity of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3672e5-73e1-43b6-a92d-d8fd85c180f0",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613be81f-98da-405a-9436-e733157b09e2",
   "metadata": {},
   "source": [
    "Ans: Handling missing data in a repeated measures ANOVA is crucial to obtaining valid and reliable results. There are several methods for dealing with missing data, each with its own assumptions and potential consequences. Here are some common approaches and their considerations:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion):**\n",
    "   - **Handling:** Exclude cases with missing data from the analysis.\n",
    "   - **Considerations:**\n",
    "     - Simple but may lead to loss of statistical power and biased results if missing data is not completely at random.\n",
    "     - Assumes that missingness is unrelated to the unobserved values.\n",
    "\n",
    "2. **Pairwise Deletion (Available Case Analysis):**\n",
    "   - **Handling:** Use all available data for each pairwise comparison.\n",
    "   - **Considerations:**\n",
    "     - Avoids complete exclusion but can introduce biases if missingness is related to the unobserved values.\n",
    "     - May lead to varying sample sizes for different comparisons.\n",
    "\n",
    "3. **Mean Imputation:**\n",
    "   - **Handling:** Replace missing values with the mean of observed values for the variable.\n",
    "   - **Considerations:**\n",
    "     - Preserves the sample size but may underestimate the variability and distort relationships.\n",
    "     - Assumes missing values have the same mean as observed values.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF):**\n",
    "   - **Handling:** Impute missing values with the last observed value for that participant.\n",
    "   - **Considerations:**\n",
    "     - Suitable for longitudinal data with a clear temporal sequence.\n",
    "     - Assumes that the last observed value is representative of the unobserved values.\n",
    "\n",
    "5. **Linear Interpolation:**\n",
    "   - **Handling:** Estimate missing values based on linear interpolation between observed values.\n",
    "   - **Considerations:**\n",
    "     - Appropriate for data with a linear trend.\n",
    "     - Assumes a linear relationship between observed values.\n",
    "\n",
    "6. **Multiple Imputation:**\n",
    "   - **Handling:** Generate multiple imputed datasets, each with different imputed values.\n",
    "   - **Considerations:**\n",
    "     - Preserves uncertainty by accounting for variability in imputations.\n",
    "     - Requires careful consideration of model assumptions and may be computationally intensive.\n",
    "\n",
    "**Potential Consequences of Different Methods:**\n",
    "\n",
    "- **Bias:** Some methods can introduce bias if the missingness is related to the unobserved values.\n",
    "- **Efficiency:** Complete case deletion may result in reduced statistical power compared to imputation methods.\n",
    "- **Precision:** Imputation methods may provide more precise estimates but introduce uncertainty due to the imputation process.\n",
    "- **Validity:** The choice of method depends on the assumptions and the nature of the missing data, and validity may be compromised if assumptions are violated.\n",
    "\n",
    "It's important to carefully consider the nature of the missing data and the assumptions of the chosen method. Sensitivity analyses, comparing results across different methods, can provide insights into the robustness of the findings. Consulting statistical experts or methodologists can be valuable when dealing with missing data in complex analyses like repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba574d-647d-4efb-b7ad-eb9bc6023621",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b196a98-e341-4157-95ee-ebe415d1d407",
   "metadata": {},
   "source": [
    "Ans: After conducting an Analysis of Variance (ANOVA) and finding a significant difference among group means, post-hoc tests are often used to identify specific group differences. Some common post-hoc tests include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD):**\n",
    "   - **When to Use:** Tukey's HSD is used when you have three or more groups, and you want to compare all possible pairs of group means.\n",
    "   - **Example:** In a study comparing the effectiveness of three different teaching methods, a significant difference was found using ANOVA. Tukey's HSD can be used to identify which pairs of teaching methods are significantly different.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **When to Use:** Bonferroni correction is suitable when making multiple comparisons, and it adjusts the significance level to control the familywise error rate.\n",
    "   - **Example:** In a clinical trial with four treatment groups, multiple pairwise comparisons may be performed using Bonferroni correction to maintain an overall significance level.\n",
    "\n",
    "3. **Duncan's New Multiple Range Test:**\n",
    "   - **When to Use:** Duncan's test is another option for comparing group means after ANOVA. It compares all possible pairs of means, similar to Tukey's HSD.\n",
    "   - **Example:** In an agricultural study comparing the yields of different fertilizer treatments, Duncan's test can be used to identify which specific fertilizers resulted in significantly different yields.\n",
    "\n",
    "4. **Scheffé's Method:**\n",
    "   - **When to Use:** Scheffé's method is a conservative post-hoc test that is suitable for comparing all possible pairs of means. It is less sensitive to Type I errors but may have lower power.\n",
    "   - **Example:** In a social science study examining the effects of different interventions on anxiety levels, Scheffé's method can be applied to assess pairwise differences.\n",
    "\n",
    "5. **Games-Howell Test:**\n",
    "   - **When to Use:** Games-Howell is a robust post-hoc test that is appropriate when group variances are unequal. It does not assume equal variances across groups.\n",
    "   - **Example:** In a medical study comparing the effects of different medications on blood pressure, Games-Howell can be used if the variances in blood pressure measurements are not equal.\n",
    "\n",
    "**Example Situation Requiring a Post-hoc Test:**\n",
    "Suppose a researcher conducts a one-way ANOVA to compare the performance of students who were taught using three different teaching methods. The ANOVA reveals a statistically significant difference in performance among the three groups. To pinpoint which specific teaching methods led to significant differences, a post-hoc test like Tukey's HSD or Duncan's New Multiple Range Test can be applied.\n",
    "\n",
    "In this scenario, the post-hoc test helps avoid making overly conservative conclusions and provides a more nuanced understanding of the differences between the teaching methods. Without a post-hoc test, the ANOVA alone only indicates the presence of a significant difference but does not identify where the differences lie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a4e13-79cd-46e7-a1e9-9292a9727e1c",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36d94dd-7bf9-4e35-b011-1d30efb475be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 8.83143761769081\n",
      "P-value: 0.00023880342850159922\n",
      "Reject the null hypothesis. There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate random weight loss data for three diets\n",
    "np.random.seed(123)  # for reproducibility\n",
    "weight_loss_A = np.random.normal(loc=5, scale=2, size=50)\n",
    "weight_loss_B = np.random.normal(loc=6, scale=2, size=50)\n",
    "weight_loss_C = np.random.normal(loc=4, scale=2, size=50)\n",
    "\n",
    "# Combine data into a single array\n",
    "all_weight_loss_data = np.concatenate([weight_loss_A, weight_loss_B, weight_loss_C])\n",
    "\n",
    "# Create group labels\n",
    "group_labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(weight_loss_A, weight_loss_B, weight_loss_C)\n",
    "\n",
    "# Print results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f68b4-eaee-4e52-9528-9ed9affd8872",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653cce2a-ff09-42a3-8871-6d8e991da265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   sum_sq    df         F    PR(>F)\n",
      "C(Program)                      11.287858   2.0  0.854435  0.429188\n",
      "C(ExperienceLevel)               0.767752   1.0  0.116230  0.734011\n",
      "C(Program):C(ExperienceLevel)   10.393583   2.0  0.786743  0.458651\n",
      "Residual                       554.857836  84.0       NaN       NaN\n",
      "\n",
      "Main Effect of Program: F = 0.8544351373407737, p = 0.4291880727516585\n",
      "Main Effect of Experience Level: F = 0.11623007731503869, p = 0.7340110486576541\n",
      "Interaction Effect: F = 0.7867429166288319, p = 0.4586513066311829\n",
      "There is no significant main effect of Software Program.\n",
      "There is no significant main effect of Experience Level.\n",
      "There is no significant interaction effect between Software Program and Experience Level.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate random data for demonstration\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "# Software programs: A, B, C\n",
    "programs = np.random.choice(['A', 'B', 'C'], size=90)\n",
    "\n",
    "# Employee experience level: Novice, Experienced\n",
    "experience_level = np.random.choice(['Novice', 'Experienced'], size=90)\n",
    "\n",
    "# Time taken to complete the task\n",
    "time_taken = np.random.normal(loc=10, scale=2, size=90)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Program': programs, 'ExperienceLevel': experience_level, 'TimeTaken': time_taken})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'TimeTaken ~ C(Program) + C(ExperienceLevel) + C(Program):C(ExperienceLevel)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effects\n",
    "main_effect_program = anova_table.loc['C(Program)', 'F']\n",
    "main_effect_experience = anova_table.loc['C(ExperienceLevel)', 'F']\n",
    "interaction_effect = anova_table.loc['C(Program):C(ExperienceLevel)', 'F']\n",
    "\n",
    "# P-values\n",
    "p_value_program = anova_table.loc['C(Program)', 'PR(>F)']\n",
    "p_value_experience = anova_table.loc['C(ExperienceLevel)', 'PR(>F)']\n",
    "p_value_interaction = anova_table.loc['C(Program):C(ExperienceLevel)', 'PR(>F)']\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nMain Effect of Program: F = {main_effect_program}, p = {p_value_program}\")\n",
    "print(f\"Main Effect of Experience Level: F = {main_effect_experience}, p = {p_value_experience}\")\n",
    "print(f\"Interaction Effect: F = {interaction_effect}, p = {p_value_interaction}\")\n",
    "\n",
    "# Check for significance based on p-values and alpha level\n",
    "if p_value_program < alpha:\n",
    "    print(\"There is a significant main effect of Software Program.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Software Program.\")\n",
    "\n",
    "if p_value_experience < alpha:\n",
    "    print(\"There is a significant main effect of Experience Level.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience Level.\")\n",
    "\n",
    "if p_value_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between Software Program and Experience Level.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Software Program and Experience Level.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644d24d-6b7b-4939-817b-ad94c6489757",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34561962-f832-4aeb-9f33-9b8bca9a8299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "T-statistic: -3.0316172004188147\n",
      "P-value: 0.0027577299763983324\n",
      "\n",
      "Post-hoc test results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Generate random test scores for demonstration\n",
    "np.random.seed(123)  # for reproducibility\n",
    "control_group_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_group_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Print t-test results\n",
    "print(f\"Two-sample t-test results:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Follow up with post-hoc test (e.g., Tukey's HSD)\n",
    "data = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "groups = ['Control'] * 100 + ['Experimental'] * 100\n",
    "posthoc_results = mc.MultiComparison(data, groups).tukeyhsd()\n",
    "\n",
    "# Print post-hoc test results\n",
    "print(\"\\nPost-hoc test results:\")\n",
    "print(posthoc_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46ce45-10dd-4a1a-906f-1b497afd4bf7",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343e5936-f464-45f3-ae43-b8fe0194e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  1.4901 2.0000 58.0000 0.2339\n",
      "===================================\n",
      "\n",
      "\n",
      "Post-hoc test results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  10.4044 0.2221  -4.4423 25.2511  False\n",
      "     A      C   6.4585 0.5555  -8.3882 21.3052  False\n",
      "     B      C  -3.9459  0.802 -18.7926 10.9008  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Generate random daily sales data for demonstration\n",
    "np.random.seed(123)  # for reproducibility\n",
    "days = 30\n",
    "sales_store_A = np.random.normal(loc=100, scale=20, size=days)\n",
    "sales_store_B = np.random.normal(loc=110, scale=15, size=days)\n",
    "sales_store_C = np.random.normal(loc=95, scale=25, size=days)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Day': np.repeat(range(1, days + 1), 3),\n",
    "    'Store': np.tile(['A', 'B', 'C'], days),\n",
    "    'Sales': np.concatenate([sales_store_A, sales_store_B, sales_store_C])\n",
    "})\n",
    "\n",
    "# Fit repeated measures ANOVA model\n",
    "rm_anova = AnovaRM(df, 'Sales', 'Day', within=['Store'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "# Print ANOVA table\n",
    "print(results.summary())\n",
    "\n",
    "# Follow up with post-hoc test (e.g., Tukey's HSD)\n",
    "posthoc_results = mc.MultiComparison(df['Sales'], df['Store']).tukeyhsd()\n",
    "\n",
    "# Print post-hoc test results\n",
    "print(\"\\nPost-hoc test results:\")\n",
    "print(posthoc_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
